# üîß Configura√ß√£o do Google Gemini Pro no Luma

## ‚úÖ Workflow Atualizado

O workflow `luma_workflow_with_tools.json` foi atualizado para usar **Google Gemini Pro** ao inv√©s do OpenAI GPT-4.

## üìã Passos para Configurar no n8n

### 1. Criar Credenciais do Google Gemini

1. **No n8n**, v√° em **Credentials** (Credenciais)
2. Clique em **Add Credential** (Adicionar Credencial)
3. Procure por **"Google Gemini(PaLM) Api"** ou **"Google PaLM API"**
4. Preencha os campos:
   - **Host**: `https://generativelanguage.googleapis.com` (j√° deve vir preenchido)
   - **API Key**: Cole sua chave API do Google Gemini
     - Esta √© a chave que voc√™ viu no Google AI Studio: `AIzaSyCTWpMG3b01_9uafb61FK3SgU6nsu6px98`
   - **Allowed HTTP Request Domains**: Deixe como "All" (ou configure conforme necess√°rio)
5. Clique em **Test Connection** (Testar Conex√£o) para verificar
6. Clique em **Save** (Salvar)
7. D√™ um nome descritivo, exemplo: **"Google Gemini Luma"**

### 2. Atualizar o Workflow no n8n

1. **Importe o workflow atualizado** (`luma_workflow_with_tools.json`) no n8n
2. **Abra o workflow**
3. **Clique no n√≥ "Google Gemini Pro"**
4. **Na se√ß√£o "Credential to connect with"**, selecione as credenciais que voc√™ acabou de criar
5. **Verifique o modelo selecionado**:
   - Padr√£o: `models/gemini-1.5-pro` (recomendado para Pro)
   - Alternativas dispon√≠veis:
     - `models/gemini-2.5-flash` (mais r√°pido, ainda em beta)
     - `models/gemini-1.5-flash` (r√°pido e econ√¥mico)
     - `models/gemini-pro` (vers√£o anterior)
6. **Ajuste as op√ß√µes se necess√°rio**:
   - **Temperature**: 0.7 (padr√£o, controla criatividade)
   - **Max Output Tokens**: 1500 (padr√£o)
7. **Salve o workflow**

### 3. Modelos Dispon√≠veis

O n8n carrega dinamicamente os modelos dispon√≠veis na sua conta do Google Gemini. Voc√™ pode ver todos os modelos dispon√≠veis clicando no dropdown "Model" no n√≥.

**Modelos Recomendados para Tool Calling:**
- ‚úÖ `models/gemini-1.5-pro` - **RECOMENDADO** - Melhor qualidade, suporta tool calling
- ‚úÖ `models/gemini-2.5-flash` - Mais r√°pido, experimental, suporta tool calling
- ‚úÖ `models/gemini-1.5-flash` - R√°pido e econ√¥mico, suporta tool calling
- ‚ö†Ô∏è `models/gemini-pro` - Vers√£o anterior, pode ter limita√ß√µes

**Nota:** Todos os modelos Gemini 1.5+ suportam **Function Calling** (tool calling), que √© essencial para o AI Agent funcionar com as ferramentas (Financial Summary, Tasks, etc.).

### 4. Testar o Workflow

1. **Ative o workflow** (toggle no canto superior direito)
2. **Teste enviando uma mensagem** do app Luma
3. **Verifique os logs** se houver erro:
   - Certifique-se que a API Key est√° correta
   - Verifique que o modelo selecionado existe na sua conta
   - Confirme que as tool workflows est√£o criadas e ativas

### 5. Troubleshooting

**Erro: "Invalid API Key"**
- Verifique se a chave est√° correta (come√ßa com `AIza...`)
- Confirme que a chave est√° ativa no Google AI Studio

**Erro: "Model not found"**
- O modelo pode n√£o estar dispon√≠vel na sua conta
- Tente usar `models/gemini-1.5-flash` (dispon√≠vel para todos)

**Erro: "Tool calling not supported"**
- Certifique-se de usar Gemini 1.5+ (`gemini-1.5-pro` ou `gemini-1.5-flash`)
- Vers√µes antigas do Gemini n√£o suportam function calling

**O Agent n√£o est√° usando as ferramentas:**
- Verifique que todas as tool workflows est√£o criadas e ativas
- Confirme que os IDs dos workflows est√£o corretos no n√≥ "Tool Workflow"

## üéØ Vantagens do Gemini Pro

- ‚úÖ **Mais econ√¥mico** que GPT-4
- ‚úÖ **Boa qualidade** de respostas
- ‚úÖ **Suporte completo a tool calling**
- ‚úÖ **Context window grande** (at√© 1 milh√£o de tokens no 1.5 Pro)
- ‚úÖ **Lat√™ncia baixa** com modelos Flash

## üìù Nota Importante

Se voc√™ quiser usar o modelo **Gemini 2.5 Flash** (mais recente e r√°pido), altere:
- `models/gemini-1.5-pro` ‚Üí `models/gemini-2.5-flash`

Mas lembre-se que o 2.5 Flash ainda est√° em vers√£o experimental, ent√£o o 1.5 Pro √© mais est√°vel para produ√ß√£o.

---

**Pronto!** Agora o Luma est√° usando Google Gemini Pro! üéâ

